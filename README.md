# Toxic Comment Classification

This project implements a machine learning model to classify toxic comments using Natural Language Processing (NLP) techniques. The model is designed to identify and categorize different types of toxic content in text data. Dataset from: https://www.kaggle.com/competitions/jigsaw-toxic-comment-classification-challenge/data

## Project Overview

The project uses a Jupyter notebook (`Toxic_Comment_Classification.ipynb`) that contains the complete implementation of:
- Data preprocessing and cleaning
- Text vectorization
- Model training and evaluation
- Toxic comment classification

## Features

- Text preprocessing and cleaning
- Implementation of machine learning models for toxic comment classification
- Model evaluation metrics
- Interactive notebook with detailed explanations

## Requirements

To run this project, you'll need:
- Python 3.x
- Jupyter Notebook
- Required Python packages (will be listed in requirements.txt)

## Getting Started

1. Clone this repository:
```bash
git clone (https://github.com/Hayrambh/NLP_ToxicComments)
```

2. Install the required dependencies:
```bash
pip install -r requirements.txt
```

3. Open the Jupyter notebook:
```bash
jupyter notebook Toxic_Comment_Classification.ipynb
```

## Usage

The notebook contains detailed explanations and code cells that you can run sequentially to:
1. Load and preprocess the data
2. Train the classification model
3. Evaluate the model's performance
4. Make predictions on new comments

## License

This project is licensed under the MIT License - see the LICENSE file for details.

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request. 
